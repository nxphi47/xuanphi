#!/bin/env python2

# ------------------------------
# svm-train.py
#	train the svm according to the input training samples
# ------------------------------

import json, sys, os
import svmclassifier as SVM
import utils
from copy import deepcopy

FEATURES = ['normTimeWidth', 'peakValue', 'totalArea', 'peakTime', '+gradRatio', '-gradRatio', '0gradRatio',
			'peakWidthDiff', 'peakWidthDiv', 'peakValueDiv', 'areaRatio', 'refTimeWidth-ave', 'refTimeWidth-immed', 
			'refTimeWidth-grad', 'gradChange' ]
SMOOTH = 3
DIVIDER = 'split'

def usage():
	print "Usage: %s <infile> <label>" % sys.argv[0]
	print "\tTrain an SVM with the training samples and vary the features used\n"
	print "Parameters:"
	print "\t<infile>: the input file generated by process-json.py\n"
	print "\t<label>: the labels used to save the training samples and svm\n"
	print
	exit(0)

feature_cnt = 1

def process_one (infname, outlabel, resf, feature_cnt):
	# Generate Features
	features = []
	f_str = ''
	for i,f in enumerate(FEATURES):
		if feature_cnt & (2**i) > 0:
			features.append(FEATURES[i])
			f_str = '1' + f_str
		else:
			f_str = '0' + f_str
	if len(features) < 2:
		# minimum 2 features
		return None
	print "\n****************************************************"
	print "Generated feature(%d:%s)=%s" % (feature_cnt, f_str, repr(features))
	print "***************************************************"
	# Generate Training Samples
	inf = open(infname, 'r')
	_root = os.path.dirname(infname)
	fname = "%s-%d" % (outlabel, feature_cnt)
	outfname = os.path.join(_root, fname)
	trainf = open(outfname + '.samples', 'w')
	testf =  open(outfname + '.samples.test', 'w')
	gen_training_sample(inf, trainf, testf, features, 6)
	inf.close()
	trainf.close()
	testf.close()
	print "\n**************************************************"
	print "Generated training samples in %s.samples" % outfname
	print "**************************************************"
	# SVM Training
	resf.write("\n-----------------------------------------\n")
	resf.write("Evaluating feature set = %s\n" % repr(features))
	resf.write("  - samples: %s.samples" % outfname)
	resf.write("  - SVM:     %s.svm" % outfname)
	ret = svm_train (outfname + '.samples', outfname + '.svm', resf)
	ret['features'] = features
	ret['output'] = outfname
	return ret
	
def gen_training_sample(inf, trainf, testf, features, ntest):
	labels={}
	dataID=[]
	datafv=[]
	lists=[]
	FILENAME=''
	if SMOOTH == 1:
		while True:
			sample = utils.get_sample(inf, features)
			if not sample:
				break
			if not sample.has_key('fv'):
				continue
			if not sample['label'] in labels:
				labels[sample['label']] = 0
			labels[sample['label']] += 1
			if labels[sample['label']] == ntest:
				labels[sample['label']] = 0
				testf.write(json.dumps(sample) + '\n')
			else:
				trainf.write(json.dumps(sample) + '\n')
	else:
		while True:
			sample = utils.get_sample(inf, features)
			if not sample:
				break
			if not sample.has_key('fv'):
				continue
			if len(FILENAME) < 1 or not sample['filename'] == FILENAME:
				FILENAME = sample['filename']
				dataID = []
				datafv = []
			dataID.append(sample['id'])
			datafv.append(sample['fv'])
			if len(dataID) == SMOOTH:
				_dict={}
				_dict['id'] = dataID[0]
				_dict['joint-id'] = dataID
				_dict['filename'] = FILENAME
				_l = []
				for i in datafv:
					_l.extend(i)
				_dict['fv'] = _l
				#_dict['fv'] = datafv
				_dict['label'] = sample['label']
				#_odict = collections.OrderedDict(sorted(_dict.items()))
				lists.append(deepcopy(_dict))
				dataID.pop(0)
				datafv.pop(0)
		
		if DIVIDER == 'split':
			# get list of filename from list of dictionary
			_group = list(set([d['filename'] for d in lists if 'filename' in d]))
			
			import random
			_test_len = int(len(_group) / 6)
			#_test_json_file = random.sample(_group, _test_len)
			#_test_json_file = _group[len(_group)-_test_len:]
			_num = int(_test_len / 4)
			_remain = _test_len % _num
			_cub = _num + int(_remain / 2)
			
			_test_json_file = []
			l37, l20, l10, l7 = [], [], [], []
			for name in reversed(_group):
				if 'curb37.5' in name and len(l37) < _num:
						l37.append(name)
				if 'curb7.5' in name and len(l7) < _num:
					l7.append(name)
				if 'curb20' in name and not '-rev' in name and len(l20) < _cub:
					l20.append(name)
				if 'curb10' in name and not '-rev' in name and len(l10) < _cub:
					l10.append(name)
				if len(l37) == _num and len(l7) == _num and len(l20) == _cub and len(l10) == _cub:
					break
			_test_json_file = l7 + l10 + l20 + l37

			for l in lists:
				if l['filename'] in _test_json_file:
					testf.write(json.dumps(l) + '\n')
				else:
					trainf.write(json.dumps(l) + '\n')
		else:
			if SMOOTH > 1:
				print 'SMOOTH > 1... ', SMOOTH
				# set how to split 
				if DIVIDER == 'smooth':
					_counter = 1
					for l in lists:
						if _counter < SMOOTH:
							trainf.write(json.dumps(l) + '\n')
						else:
							testf.write(json.dumps(l) + '\n')
							_counter = 0
						_counter += 1
				elif DIVIDER == 'side':
					# get list of filename from list of dictionary
					_group = [d['filename'] for d in lists if 'filename' in d]
					
					# get number of sample occur with same filename
					from collections import Counter
					c = Counter(_group)
					
					_counter = 0
					_filename = ''
					for l in lists:
						if len(FILENAME) < 1 or not l['filename'] == FILENAME:
							FILENAME = l['filename']
							_counter = 0
						_lnum = c[l['filename']]
						_num = int(_lnum / SMOOTH)
						# make sure always most middle sample choose
						if _lnum & 1 and _lnum > 4:
							_num += 1
						if not _counter == _num:
							trainf.write(json.dumps(l) + '\n')
						else:
							testf.write(json.dumps(l) + '\n')
						_counter += 1
			

def svm_train (infname, outsvm, resf):
	ret = {}
	#samples, labels, all_labels = utils.load_training_samples(infname)
	samples, labels, ids, all_labels = utils.load_training_samples(infname)
	acc = utils.AccStats(all_labels)	
	svm = SVM.SVMClassifier('-q')
	svm.cv_train(labels, samples)
	svm.save(outsvm)
	print "\n**************************************************"
	print "SVM %s Trained" % (outsvm)
	print "**************************************************"
	pred = svm.predict(samples, labels)
	acc.update(labels, pred)
	ret['train:correct'], ret['train:wrong'] = acc.get_res()
	print 'Train_labels: ', all_labels
	acc.print_table("Training Set Accuracy:")
	acc.print_table("Training Set Accuracy:", resf)
	samples, labels, ids, all_labels = utils.load_training_samples(infname+'.test', all_labels=all_labels)
	pred = svm.predict(samples, labels)
	acc.reset()
	acc.update(labels, pred)
	print 'Test_labels: ', all_labels
	acc.print_table("Test Set Accuracy:")
	acc.print_table("Test Set Accuracy:", resf)
	ret['test:correct'], ret['test:wrong'] = acc.get_res()
	del svm
	return ret
	
def print_acc (acc, f, label=''):
	f.write("\n-----------------------------------------\n")
	if len(label)>1:
		f.write("%s:\n" % label)
	f.write("     Features:       %s\n" % repr(acc['features']))
	f.write("     Saved Output:   %s\n" % acc['output'])
	c = acc['train:correct']
	w = acc['train:wrong']
	f.write("     Train Results:  Correct=%.2f%%(%d), Wrong=%.2f%%(%d)\n" % (100.*c/(c+w), c, 100.*w/(c+w), w))
	c = acc['test:correct']
	w = acc['test:wrong']
	f.write("     Test Results:   Correct=%.2f%%(%d), Wrong=%.2f%%(%d)\n" % (100.*c/(c+w), c, 100.*w/(c+w), w))
	f.write("\n-----------------------------------------\n")

if __name__ == "__main__":
	if len(sys.argv) < 3:
		usage()
	resf = open(sys.argv[2] + "-svm-res.txt", "w")
	if not resf:
		print "Error creating %s" % sys.argv[2]
		exit(2)
		
	acc = []
	best = 0
	for fc in xrange(3, 2**len(FEATURES)):
		res = process_one(sys.argv[1], sys.argv[2], resf, fc)
		if not res:
			continue
		acc.append(res)
		if res['test:correct'] > acc[best]['test:correct']:
			best = acc.index(res)

	print_acc(acc[best], sys.stdout, 'Best')
	print_acc(acc[best], resf, 'Best')
	resf.close()
	
